{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punkmic/Text-Classification-Lab-1-Data-preparation-with-pandas/blob/master/MSDSTextClassification_Lab1_DataPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification, Lab 1: Data preparation with pandas"
      ],
      "metadata": {
        "id": "vBVrSZE47UNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ö°Ô∏è Make a Copy\n",
        "\n",
        "Save a copy of this notebook in your Google Drive before continuing. Be sure to edit your own copy, not the original notebook."
      ],
      "metadata": {
        "id": "oFjtWQGK3X-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÅ We are working toward a goal: the final project"
      ],
      "metadata": {
        "id": "SNo8f6Hb7hPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please take a moment to review the requirements for the upcoming final project for this course. This lab assignment, as well as the follow-up lab are designed to step you toward the goal of completing your final project."
      ],
      "metadata": {
        "id": "jhXh4AVX7lwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üêç Python knowledge expected"
      ],
      "metadata": {
        "id": "7dYHxxvq7-V4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lab and the remainder of this course, as well as the other courses in this Courera specialization track, all assume some prior experience in programming. Particularly, you will be using Python to solve analytics problems.\n",
        "\n",
        "If you need to brush up on your Python, please see the [Python revew notebook](https://drive.google.com/file/d/17WGK_Exij4_N3k--CKok3y8ZqE1ZsCqW/view?usp=sharing). You should understand and be familiar with all of the concepts in that notebook before moving forward."
      ],
      "metadata": {
        "id": "XhBGuUel8Gps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <img src=\"https://colab.research.google.com/img/favicon.ico\" width=20 /> Everything will be done in Google Colab"
      ],
      "metadata": {
        "id": "vFvaehjf8-vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Built on top of the [jupyter project](https://jupyter.org/), Google's Colab notebook environment is both a great learning resource and an excellent platform for programmatic analytics.\n",
        "\n",
        "Unless you are already familiar with Colab, please be sure to peruse the [Intro to Colab notebook](https://drive.google.com/file/d/1niGuXfN8KWL9NAvIuJf4IITO0qi2xQQb/view?usp=sharing)"
      ],
      "metadata": {
        "id": "wMNfc5WB_jkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üö¶ Getting started"
      ],
      "metadata": {
        "id": "JGegU1SBBdFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This and other labs will have the following workflow:\n",
        "\n",
        "**Do the steps.**\n",
        "\n",
        "Work through the notebook step-by-step and execute the code along the way. Be sure you understand what is happening at each step. Don't move on without understanding what the code is doing.\n",
        "\n",
        "**Answer the questions.**\n",
        "\n",
        "Through the lab, there will be a handful of questions for you to answer. These are designed to check that you are following along and to assess your understanding. The answers to these questions should be entered into the Lab quiz, available in the course after this lab assignment."
      ],
      "metadata": {
        "id": "LG_SIwzgAP6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìì About this lab"
      ],
      "metadata": {
        "id": "ZXuMewVjCBYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get started on working toward the goal of completing your project, the two lab notebooks will step you into the building of a classification model with KTrain. These exercises will be nearly identical to the lectures, so be sure to watch those videos.\n",
        "\n",
        "For this lab, you will just complete the pre-processing of data, using the popular Pandas library to manipulate the data.\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8ERHzPAZCE9t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGSUArJ_ZYN3"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to be using Google's Tensorflow package: \n",
        "https://www.tensorflow.org/tutorials\n",
        "\n",
        "We're using an API wrapper for Tensorflow called ktrain. It's absolutely fabulous because it really abstracts the whole deep learning process into a workflow so easy, even a computational social scientist can do it:\n",
        "https://github.com/amaiya/ktrain"
      ],
      "metadata": {
        "id": "Y0MIZDrs0Ddx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16hoKG5dbeWs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "WGH867GCwvOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1Z0VbCzGwkDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set your google colab runtime to use GPU, a must for deep learning!\n",
        "\n",
        "Runtime > Change Runtime Type > GPU\n",
        "\n",
        "The following code snippet will show you GPU information for your runtime."
      ],
      "metadata": {
        "id": "E3XGSpfy0xPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "I0GWta-7ELIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9904766e-412b-4ba6-d2fe-4f078eb42807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb  2 00:07:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data"
      ],
      "metadata": {
        "id": "oLd-Qkl7Djha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project, we're going to be using data from Kaggle. Whenever you're on the hunt for some data to play around with in the predictive modeling word, Kaggle's database of datasets is a great place to poke around. Our data comes from Kaggle's News Category database: https://www.kaggle.com/rmisra/news-category-dataset/version/2\n",
        "\n",
        "For this lab, we will use a version of this data which has been converted from .jsonl to json format which works well with pandas. The modified data file is available in the course assets.\n",
        "\n",
        "‚§µÔ∏è **Before moving forward:** download the data file from the course assets and upload it to the root of your Google Drive."
      ],
      "metadata": {
        "id": "idE4-ojt0-dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = pd.read_json(\"drive/MyDrive/news_category_trainingdata.json\")"
      ],
      "metadata": {
        "id": "a7mhLblG6saq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8a876eab-95b5-4f9d-9fc6-f67a0d084200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-eaf18ed8b678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/news_category_trainingdata.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m             )\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected object or value"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìÅ Mount Google Drive"
      ],
      "metadata": {
        "id": "aEtJHb0dzOO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the folder icon in the left side-bar, then the Mount Drive icon. Colab will either mount the Drive for you, or will place a code snippet into the notebook which will mount the drive when executed."
      ],
      "metadata": {
        "id": "qlqjuFE8zSle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the data"
      ],
      "metadata": {
        "id": "x-NXTV--Y3ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.head()"
      ],
      "metadata": {
        "id": "quwyVcHh6P1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data"
      ],
      "metadata": {
        "id": "HbCERZaXG0p-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most machine learning tools in Python accept one field/column/string. So we have to merge our two text column. Let's separate it with a space."
      ],
      "metadata": {
        "id": "fZ7xO9Aa6iyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['combined_text'] = reviews['headline'] + ' ' + reviews['short_description']"
      ],
      "metadata": {
        "id": "F6VLEzaSuDyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we need to do is prepare the data. Specifically, we have a categorical column that we want to turn into a \"is this article healthy living?\" column. That is, when an article is about healthy living, it should have a 1, when it's anything else, it should be a 0."
      ],
      "metadata": {
        "id": "YKvESWUF5f4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews[reviews['category'].str.contains(\"HEALTHY LIVING\")]"
      ],
      "metadata": {
        "id": "Bz1PoZOPriCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üßê Lab Quiz Question #1\n",
        "\n",
        "Precisely how many \"HEALTHY LIVING\" articles are in the data? Use the `rows x columns` information on the pandas dataframe above to determine your answer.\n",
        "\n",
        "Be sure to answer this and the remaining lab quiz questions in Lab Quiz 1.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6ppYcTL5Jsdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick pandas search shows that we have 6.7k articles that are about healthy living. The following line of code uses numpy's `where` functionality to help us recode the data. When \"Healthy Living\" appears in the \"category\" column, we'll label the \"healthy\" column with a 1. When it doesn't, it'll be 0."
      ],
      "metadata": {
        "id": "mFRSSQP550eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['healthy'] = np.where((reviews['category'] == 'HEALTHY LIVING'), 1, 0)"
      ],
      "metadata": {
        "id": "ccC1GR85suZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['healthy'].describe()"
      ],
      "metadata": {
        "id": "aexMvzhKtyDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes! We're seeing the 1's where we'd expect."
      ],
      "metadata": {
        "id": "sHXxsWHs6MUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üßê Lab Quiz Question #2\n",
        "\n",
        "Precisely how many negative-class documents (i.e. texts that are **not** labeled as \"healthy\") in this dataset? Use the count from the above `describe` and the known number of \"healthy\" documents to determine your answer.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4Z-dwnhLHxmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing the data"
      ],
      "metadata": {
        "id": "S766s41yJVdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data is very unbalanced. We have considerably more articles about healthly living than those that are not. If we give a machine learning algorithm this much negative evidence, it'll end up tuning itself to label everything as 0's more often than not. So, let's balance our data to the number of healthy living articles."
      ],
      "metadata": {
        "id": "jcnU6zeuan-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_amount =  len(reviews[reviews[\"healthy\"] == 1])\n",
        "\n",
        "healthy = reviews[reviews['healthy'] == 1]\n",
        "not_healthy = reviews[reviews['healthy'] == 0].sample(n=sample_amount)"
      ],
      "metadata": {
        "id": "xfLYND3fam_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_sample = pd.concat([healthy,not_healthy])"
      ],
      "metadata": {
        "id": "B48IOQpGdsp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_sample.describe()"
      ],
      "metadata": {
        "id": "CHr4h7FYed_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mean of .5 means these datasets are now perfectly balanced! And the N is 2x the number of healthy-living articles."
      ],
      "metadata": {
        "id": "0DoFeOx8eniJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üßê Lab Quiz Question #3\n",
        "\n",
        "What is the final count of all data samples in the balanced dataset?\n",
        "\n",
        "Use the count from the `describe` above to determine your answer.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-_gKMIReLOVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving on to Lab 2"
      ],
      "metadata": {
        "id": "oW6feK8MlO8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Lab 2, you will do a quick pass through the code above, and then pick up from this point to train your text classification model."
      ],
      "metadata": {
        "id": "Da30cxU2lRHc"
      }
    }
  ]
}